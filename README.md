#### 大数据作业3-微博热搜实时数据可视化-说明文档
小组成员：李傲、傅友、曾友雯

###### 1. 需要说明的内容

  本项目是一个数据可视化的再现和改造，参考[Jannchie](https://github.com/Jannchie)的开源可视化框架[Historical-ranking-data-visualization-based-on-d3.js ](https://github.com/Jannchie/Historical-ranking-data-visualization-based-on-d3.js)以及[Moying-moe](https://github.com/Moying-moe)的python实现的上述项目的再现[python_ranking_visualization_based_on_pygame](https://github.com/Moying-moe/python_ranking_visualization_based_on_pygame)。
  自己在参考(copy)上述代码的时候又写了一个小小的爬虫，主要是爬取新浪微博的热搜榜，最初的版本是爬虫爬取新浪微博热搜的内容存到文件中(.csv)文件，然后可视化代码部分从文件中读取内容进行动态可视化展示，这只是最初的方案(如果想要使用这种办法，只需要把本项目的代码克隆到本地，然后使用Git回退到第一次提交的时候的版本就可以使用，或者直接查看提交记录，找到第一次提交的时候的代码就可以了)；
  后来进行的改造是将爬虫代码和数据可视化代码进行综合到一起，使得整个项目在运行时可以实时展示，就是爬虫爬取的新浪微博热搜的内容不再往文件中存储，而是通过函数接口直接传递给数据可视化部分进行可视化展示，最终的效果就是实时动态可以展示新浪微博热搜的内容变化。
  
--------------------

###### 2. 存在的问题以及可以改进的地方
  1. 爬虫爬取速率的问题，本机测试的时候爬虫的最快爬取速率大致为每2-3秒爬取一次，这种速率比较低，但是实测不会被新浪封IP，并不需要考虑使用IP代理问题，考虑到整个项目的复杂性，这里并没有使用`Scrapy`框架，框架使用案例可以参照自己之前写的[知乎用户信息的爬虫](https://github.com/liyuanshuo/zhihu_spider)，如果追求高时效性可以使用框架进行数据的爬取，使用框架的时候可以直接将数据存储到数据库`Redis`或者其他数据库，但是在使用框架的需要考虑到反爬虫的问题，对于新浪或者知乎这种比较大的网站，如果要反反爬虫，更换代理头并不可行，最好的办法就是使用IP代理池(免费的IP代理池实测只有不到5%的IP地址可用)，
  2. 数据传递问题，这里的数据传递直接是采用的变量传递，并且每次爬取都会进行传递，每次传递的时候为了保证显示效果并没有把之前存储在内存中的数据清楚，对于数据量比较小的时候非常方便使用，如果需要传递的数据比较大的时候，再使用变量传递就会非常占用内存空间，对于数据量较的情况的，较好的解决办法就是使用实时的数据库进行数据传递。
  3. 数据展示的时候目前仍然存在一些问题，就是每次数据变化的时间间隔大致为2-3秒，但是在展示数据的的变化的时候经常会出现跳变，并不连续，主要原因还是数据存储问题，这里使用的存储方式存在问题，主要是懒和笨，勉强看懂的参考代码，但是没有做太大幅度的修改，在理清楚代码的思路后，发现要想做到自己想要的结果，需要对代码进行重构，由于时间原因，这里放弃代码重构。
  4. 只能展示数据，不能提供数据的回放，思考了一下，这里又需要数据库，对数据进行回访主要是查看历史数据，这里并没有对数据进行存储，如果加上数据库的话，实现数据的回放又需要对整个项目的逻辑和结构进行重新修改，对代码进行重构，所以，时间原因，虽然想做，但是大作业不止这一个啊！！！！！！！！！！！！！！！！！！！！！
  5. 视频存储也没有，本来想加上的，还是时间不够...................................应该早一点准备这个大作业的，不然可以做的更好，目前只是一个残次品.........................

---------------------

###### 3. 其他问题

具体API文档就不写了，代码比较简单，基本注释都可以说清楚，按照标准来说应该要写的，但是自己乱写的就不按标准了。。。

-----------------------

###### 4. 还有
如果哪位大佬有兴趣，热烈欢迎`commit`
